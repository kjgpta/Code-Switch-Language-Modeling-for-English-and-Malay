{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Normalizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Code for Normalizing Conversational English data and converting it to Malay"
      ],
      "metadata": {
        "id": "3MXpevVDipD5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZJ858I_ilgu"
      },
      "outputs": [],
      "source": [
        "# Importing the required modules\n",
        "import regex as re\n",
        "import malaya"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Operating on English Data "
      ],
      "metadata": {
        "id": "z17FFjEzlF0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function for cleaning out English Sentence"
      ],
      "metadata": {
        "id": "M68IyFyMi_4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_normalizer(input_string):\n",
        "    output_string = \"\"\n",
        "    for word in input_string.split():\n",
        "        if word[0] != \"<\" and word != \"\\n\":\n",
        "            output_string += \" \" + word\n",
        "        elif word == \"\\n\":\n",
        "            output_string += '.'\n",
        "        else:\n",
        "            output_string += ','\n",
        "    output_string = re.sub(',+', ',', output_string)\n",
        "    output_string = re.sub(' +', ' ', output_string)\n",
        "    return output_string.strip(', ')"
      ],
      "metadata": {
        "id": "oTFIBldci7tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading the conversational speech from \"imda5.txt\"\n"
      ],
      "metadata": {
        "id": "6N69IwGcjKuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('imda5.txt') as f:\n",
        "    contents = f.readlines() #contents contains array of all sentences present in file\n",
        "f.close()"
      ],
      "metadata": {
        "id": "XH4jFAuWjIzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Removing repeated words or phrases from the English text"
      ],
      "metadata": {
        "id": "ey7bWtdhkr-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"content\" array stores the sentences by removing the repeated words or phrases present in the text\n",
        "content = []\n",
        "for s in contents:\n",
        "    content.append(re.sub(r'\\b(.+)(\\s+\\1\\b)+', r'\\1', s)) #This removes the repeated words or phrases in the text"
      ],
      "metadata": {
        "id": "FSM7RBQPkrbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Normalizing the English Data"
      ],
      "metadata": {
        "id": "fVDWzJmwk8R7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"english_text\" stores normalized english text\n",
        "# \"text\" array stores normalized english sentence\n",
        "english_data = []\n",
        "english_text = \"\"\n",
        "for string in content:\n",
        "    sentence = sentence_normalizer(string)\n",
        "    english_text += sentence + '\\n'\n",
        "    english_data.append(sentence)"
      ],
      "metadata": {
        "id": "IazhRNuKk3BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saves the \"english_text\" onto a \"English_data.txt\" file\n",
        "f1 = open(\"English_Data.txt\",\"w+\")\n",
        "f1.write(english_text)\n",
        "f1.close()"
      ],
      "metadata": {
        "id": "zIzt1la4lDTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Malay Data from English Data"
      ],
      "metadata": {
        "id": "HwIl9Sd7lXi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading English to Malay translation model "
      ],
      "metadata": {
        "id": "hNzxBb9yjTFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the base model which english to malay translator onto translator variable.\n",
        "translator = malaya.translation.en_ms.transformer(model = 'base')"
      ],
      "metadata": {
        "id": "LSU7oDpIjRBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting English sentences in batches of 100 to its Malay counterpart"
      ],
      "metadata": {
        "id": "p7ZYXKmmjjox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"malay_text\" stores normalized malay sentence\n",
        "malay_text = \"\"\n",
        "for index in range(int(len(english_data)/100)): #\n",
        "    # \"subarray\" stores translated malay text on batch size of 100 sentences\n",
        "    subarray = translator.greedy_decoder(text[int(index*100):int((index+1)*100)])\n",
        "    for sentence in subarray:\n",
        "        malay_text += sentence +'\\n'"
      ],
      "metadata": {
        "id": "0dP4seuGjaKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saves the \"malay_text\" onto a \"Malay_data.txt\" file\n",
        "f2 = open(\"Malay_Data.txt\",\"w+\")\n",
        "f2.write(malay_text)\n",
        "f2.close()"
      ],
      "metadata": {
        "id": "IxdoG1GYkjDq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}