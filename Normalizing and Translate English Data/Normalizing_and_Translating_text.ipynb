{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeDLu_fMW8Cr"
      },
      "outputs": [],
      "source": [
        "!pip -q install text2digits\n",
        "!pip -q install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfbjuv2cW_8j"
      },
      "outputs": [],
      "source": [
        "# Importing the required libraries\n",
        "import contractions\n",
        "from text2digits import text2digits\n",
        "\n",
        "t2d = text2digits.Text2Digits()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_N8C2ugnXNvu"
      },
      "outputs": [],
      "source": [
        "# Reading the original english text file\n",
        "english_text = []\n",
        "with open('English.txt') as f:\n",
        "    english_text = f.readlines()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading the original english text file\n",
        "def word_analyzer(word, tag):\n",
        "    ar = \"\"\n",
        "    tag2= tag\n",
        "    if tag == \"<malay>\":\n",
        "        tag2 = \"</malay>\"\n",
        "    if tag == \"(\":\n",
        "        tag2 = \")\"\n",
        "    if tag == \"[\":\n",
        "        tag2 = \"]\"\n",
        "    if tag == \"<\":\n",
        "        tag2 = \">\"\n",
        "    if tag == \"{\":\n",
        "        tag2 = \"}\"\n",
        "    n = len(tag)\n",
        "    k = len(tag2)\n",
        "    if word.startswith(tag) and word.endswith(tag2):\n",
        "            ar = word[n:-k]\n",
        "    elif word.startswith(tag):\n",
        "            ar = word[n:]\n",
        "    elif word.endswith(tag2):\n",
        "            ar = word[:-k]\n",
        "    return ar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to clean the text file \n",
        "def data_cleanser(string):\n",
        "    words = string.split()\n",
        "    ar = []\n",
        "    sent = \"\"\n",
        "    for word in words:\n",
        "        if \"_\" in word:\n",
        "            wrd = \"\"\n",
        "            for j in range(len(word)):\n",
        "                if word[j] != \"_\":\n",
        "                    wrd += word[j]\n",
        "            word = wrd\n",
        "        elif word.startswith(\"<malay>\") or word.endswith(\"</malay>\"):\n",
        "            word = word_analyzer(word, \"<malay>\")\n",
        "        elif word.startswith(\"(\") or word.endswith(\")\"):\n",
        "            word = word_analyzer(word, \"(\")\n",
        "        elif word.startswith(\"[\") or word.endswith(\"]\"):\n",
        "            word = word_analyzer(word, \"[\")\n",
        "        elif word.startswith(\"<\") or word.endswith(\">\"):\n",
        "            word = word_analyzer(word, \"<\")\n",
        "        elif word.startswith(\"{\") or word.endswith(\"}\"):\n",
        "            word = word_analyzer(word, \"{\")\n",
        "        elif word.startswith(\"!\") or word.endswith(\"!\"):\n",
        "            word = word_analyzer(word, \"!\")\n",
        "        elif word.startswith(\"#\") or word.endswith(\"#\"):\n",
        "            word = word_analyzer(word, \"#\")\n",
        "        elif word.endswith(\"~\"):\n",
        "            word = word[:-1]\n",
        "        ar.append(word)\n",
        "    return \" \".join(ar)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ4zB4PXYmBp"
      },
      "outputs": [],
      "source": [
        "# Function to normalize the text file using the above user defined functions\n",
        "def text_normalize(string):\n",
        "    for k in list(\"!#$%&()*+-.:,;<=>@[]^_`{|}~\"):\n",
        "        string = string.replace(k,\"\")\n",
        "    line = \"\"\n",
        "    for j in string.split():\n",
        "        line += j + \" \"\n",
        "    eng = contractions.fix(line)\n",
        "    flag = False\n",
        "    temp = \"\"\n",
        "    line = \"\"\n",
        "    for i in eng.split():\n",
        "        if len(i) == 1:\n",
        "            flag = True\n",
        "            temp += i.upper()\n",
        "        else:\n",
        "            if flag == True:\n",
        "                if temp == \"I\" or temp == \"A\":\n",
        "                    temp = temp.lower()\n",
        "                line += temp + \" \"\n",
        "                temp = \"\"\n",
        "            if i == \"first\":\n",
        "                temp = \"1st\"\n",
        "            elif i == \"second\":\n",
        "                temp = \"2nd\"\n",
        "            elif i == \"third\":\n",
        "                temp = \"3rd\"\n",
        "            elif i == \"fourth\":\n",
        "                temp = \"4th\"\n",
        "            elif i == \"fifth\":\n",
        "                temp = \"5th\"\n",
        "            elif i == \"sixth\":\n",
        "                temp = \"6th\"\n",
        "            elif i == \"seventh\":\n",
        "                temp = \"7th\"\n",
        "            elif i == \"eighth\":\n",
        "                temp = \"8th\"\n",
        "            elif i == \"ninth\":\n",
        "                temp = \"9th\"\n",
        "            elif i == \"oh\":\n",
        "                temp = \"ohh\"\n",
        "            else: \n",
        "                temp = i\n",
        "            flag = False\n",
        "        if flag == False:\n",
        "            line += temp + \" \"\n",
        "            temp = \"\"\n",
        "    if flag == True:\n",
        "        line += temp\n",
        "\n",
        "    return t2d.convert(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe35cMlHYoIl"
      },
      "outputs": [],
      "source": [
        "# Normalize the English text\n",
        "english_data = \"\"\n",
        "for i in range(len(english_text)):\n",
        "    english_data += text_normalize(data_cleanser(english_text[i])) + \"\\n\"\n",
        "\n",
        "f1 = open(\"English_Normalized.txt\", \"w\")\n",
        "f1.write(english_data)\n",
        "f1.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Adkn4zptZHaY"
      },
      "outputs": [],
      "source": [
        "# Installing and Importing required libraries\n",
        "!pip -q install deep-translator\n",
        "from deep_translator import GoogleTranslator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2SdPhVLY4u8"
      },
      "outputs": [],
      "source": [
        "english_text = []\n",
        "with open('English_Normalized.txt') as f:\n",
        "    english_text = f.readlines()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19Grj1XCZCgS"
      },
      "outputs": [],
      "source": [
        "# Translating Normalized English Data to Malay\n",
        "malay_text = \"\"\n",
        "for i in range(len(english_text)):\n",
        "    malay_text += GoogleTranslator(source='en', target='ms').translate(english_text[i]) + \"\\n\"\n",
        "\n",
        "f1 = open(\"Malay_Normalized.txt\", \"w\")\n",
        "f1.write(malay_text)\n",
        "f1.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5 (default, Sep  4 2020, 02:22:02) \n[Clang 10.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "75e1efb84c03986af0e8f42485fed0cce10a00d55878541b86dc1dc64e57af84"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
