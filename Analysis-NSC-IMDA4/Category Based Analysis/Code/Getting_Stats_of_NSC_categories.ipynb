{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generates stats of the various categories "
      ],
      "metadata": {
        "id": "qBcOD32WBV9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "kbPeJN0_A5Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pzlr103nAUSd"
      },
      "outputs": [],
      "source": [
        "def detector(line):\n",
        "    if line.startswith(\"<malay>\") and line.endswith(\"</malay>\"):\n",
        "        if line.count(\"<malay>\") == 1:\n",
        "            return \"MS\"\n",
        "        else:\n",
        "            return \"CS\"\n",
        "    else:\n",
        "        if line.count(\"<malay>\") >= 1:\n",
        "            return \"CS\"\n",
        "        else:\n",
        "            return \"EN\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_analyzer(word, tag):\n",
        "    ar = \"\"\n",
        "    tag2= tag\n",
        "    if tag == \"<malay>\":\n",
        "        tag2 = \"</malay>\"\n",
        "    if tag == \"(\":\n",
        "        tag2 = \")\"\n",
        "    if tag == \"[\":\n",
        "        tag2 = \"]\"\n",
        "    if tag == \"<\":\n",
        "        tag2 = \">\"\n",
        "    if tag == \"{\":\n",
        "        tag2 = \"}\"\n",
        "    n = len(tag)\n",
        "    k = len(tag2)\n",
        "    if word.startswith(tag) and word.endswith(tag2):\n",
        "            ar = word[n:-k]\n",
        "    elif word.startswith(tag):\n",
        "            ar = word[n:]\n",
        "    elif word.endswith(tag2):\n",
        "            ar = word[:-k]\n",
        "    return ar"
      ],
      "metadata": {
        "id": "m-242Ip_Abmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_cleanser(string):\n",
        "    words = string.split()\n",
        "    eng_ar = []\n",
        "    mal_ar = []\n",
        "    flag2 = False\n",
        "    eng = \"\"\n",
        "    mal = \"\"\n",
        "    ar = []\n",
        "    sent = \"\"\n",
        "    for i in range(len(words)):\n",
        "        word = words[i]\n",
        "        if \"_\" in word:\n",
        "            wrd = \"\"\n",
        "            for j in range(len(word)):\n",
        "                if word[j] != \"_\":\n",
        "                    wrd += word[j]\n",
        "            word = wrd\n",
        "            if flag2:\n",
        "                mal += word+ \" \"\n",
        "            else:\n",
        "                eng += word+ \" \"\n",
        "        elif word.startswith(\"<malay>\") or word.endswith(\"</malay>\"):\n",
        "            word2 = word\n",
        "            if word.startswith(\"<malay>\"):\n",
        "                flag2 = True\n",
        "                eng_ar.append(eng)\n",
        "                eng = \"\"\n",
        "            word = word_analyzer(word, \"<malay>\")\n",
        "            mal += word+ \" \"\n",
        "            if word2.endswith(\"</malay>\"):\n",
        "                flag2 = False\n",
        "                mal_ar.append(mal)\n",
        "                mal = \"\"\n",
        "        elif word.startswith(\"(\") or word.endswith(\")\"):\n",
        "            word = word_analyzer(word, \"(\")\n",
        "            if flag2:\n",
        "                mal += word+ \" \"\n",
        "            else:\n",
        "                eng += word+ \" \"\n",
        "        elif word.startswith(\"[\") or word.endswith(\"]\"):\n",
        "            word = word_analyzer(word, \"[\")\n",
        "            if flag2:\n",
        "                mal += word+ \" \"\n",
        "            else:\n",
        "                eng += word+ \" \"\n",
        "        elif word.startswith(\"<\") or word.endswith(\">\"):\n",
        "            word = word_analyzer(word, \"<\")\n",
        "            if flag2:\n",
        "                mal += word+ \" \"\n",
        "            else:\n",
        "                eng += word+ \" \"\n",
        "        elif word.startswith(\"{\") or word.endswith(\"}\"):\n",
        "            word = word_analyzer(word, \"{\")\n",
        "            if flag2:\n",
        "                mal += word+ \" \"\n",
        "            else:\n",
        "                eng += word+ \" \"\n",
        "        elif word.startswith(\"!\") or word.endswith(\"!\"):\n",
        "            word = word_analyzer(word, \"!\")\n",
        "            if flag2:\n",
        "                mal += word+ \" \"\n",
        "            else:\n",
        "                eng += word+ \" \"\n",
        "        elif word.startswith(\"#\") or word.endswith(\"#\"):\n",
        "            word = word_analyzer(word, \"#\")\n",
        "            if flag2:\n",
        "                mal += word+ \" \"\n",
        "            else:\n",
        "                eng += word+ \" \"\n",
        "        elif word.endswith(\"~\"):\n",
        "            continue\n",
        "        else:\n",
        "            if flag2:\n",
        "                mal += word+ \" \"\n",
        "            else:\n",
        "                eng += word+ \" \"\n",
        "        ar.append(word)\n",
        "    if mal == \"\" and eng != \"\":\n",
        "        eng_ar.append(eng)\n",
        "    elif mal != \"\" and eng == \"\":\n",
        "        mal_ar.append(mal)\n",
        "    return eng_ar, mal_ar, \" \".join(ar)"
      ],
      "metadata": {
        "id": "irD9b1XeAdPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_length(eng_ar, mal_ar, mal_wrd, eng_wrd):\n",
        "    for eng in eng_ar:\n",
        "        eng_wrd += len(eng.split())\n",
        "    for mal in mal_ar:\n",
        "        mal_wrd += len(mal.split())\n",
        "    return mal_wrd, eng_wrd"
      ],
      "metadata": {
        "id": "3STRYxdjAgKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_stats(folder_name, name):\n",
        "    with open(folder_name+\"/\"+name+\".txt\") as f1:\n",
        "        text = f1.readlines()\n",
        "    f1.close()\n",
        "    cs_n = 0\n",
        "    mal_n = 0\n",
        "    eng_n = 0\n",
        "    mal_wrd = 0\n",
        "    eng_wrd = 0\n",
        "    cs = \"\"\n",
        "    mal = \"\"\n",
        "    eng = \"\"\n",
        "    for i in range(len(text)):\n",
        "        string = text[i][:-1]\n",
        "        lang = detector(string)\n",
        "        eng_ar, mal_ar, sent = data_cleanser(string)\n",
        "        mal_wrd, eng_wrd = get_length(eng_ar, mal_ar, mal_wrd, eng_wrd)\n",
        "        if lang == \"CS\":\n",
        "            cs += sent + \"\\n\"\n",
        "            cs_n += 1\n",
        "        if lang == \"MS\":\n",
        "            mal += sent + \"\\n\"\n",
        "            mal_n += 1\n",
        "        if lang == \"EN\":\n",
        "            eng += sent + \"\\n\"\n",
        "            eng_n += 1\n",
        "    f1 = open(folder_name+\"/cs_\"+name+\".txt\",'w+')\n",
        "    f1.write(cs)\n",
        "    f1.close()\n",
        "    f1 = open(folder_name+\"/eng_\"+name+\".txt\",'w+')\n",
        "    f1.write(eng)\n",
        "    f1.close()\n",
        "    f1 = open(folder_name+\"/mal_\"+name+\".txt\",'w+')\n",
        "    f1.write(mal)\n",
        "    f1.close()\n",
        "\n",
        "    return cs_n, mal_n, eng_n, mal_wrd, eng_wrd"
      ],
      "metadata": {
        "id": "e9dYiquIAhxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column = [\"File\", \"# CS Sentences\", \"# English Sentences\", \"# Malay Sentences\", \"# Total Sentences\", \"% CS Sentences\", \"# English Words\", \"# Malay Words\", \"# Total Words\", \"Substitution Rate(English)\", \"CMI\"]\n",
        "df = pd.DataFrame(columns = column)"
      ],
      "metadata": {
        "id": "9uVCVxDwAjqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[len(df.index)] = [\"Based on Age\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Age\", \"complete_18_30\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"18 to 30 years\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Age\", \"complete_31_45\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"31 to 45 years\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Age\", \"complete_46_more\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"46 and more \", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n"
      ],
      "metadata": {
        "id": "saPP2386AkJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[len(df.index)] = [\"Based on Gender\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Gender\", \"complete_Male\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Male\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Gender\", \"complete_Female\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Female\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n"
      ],
      "metadata": {
        "id": "TrJQG8y8AmEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[len(df.index)] = [\"Based on Relationship\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Relationship\", \"complete_Family\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Family\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Relationship\", \"complete_Friends\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Friends\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Relationship\", \"complete_Strangers\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Strangers\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n"
      ],
      "metadata": {
        "id": "nzpHTkNpAn19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[len(df.index)] = [\"Based on Ethnicity\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Ethnicity\", \"complete_Malay\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Malay\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Ethnicity\", \"complete_Indian\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Indian\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Ethnicity\", \"complete_Chinese\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Chinese\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]"
      ],
      "metadata": {
        "id": "iGqifLiUAp48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[len(df.index)] = [\"Based on Education\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Education\", \"complete_School\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"School\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Education\", \"complete_Polytechnic\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Polytechnic\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Education\", \"complete_University\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"University\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n"
      ],
      "metadata": {
        "id": "W1AOso43AsNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[len(df.index)] = [\"Based on Employment\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Employment\", \"complete_Students\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Students\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Employment\", \"complete_Unemployed\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Unemployed\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Employment\", \"complete_Employed\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "df.loc[len(df.index)] = [\"Employed\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n"
      ],
      "metadata": {
        "id": "uZaIeDqNAu5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[len(df.index)] = [\"Based on Dominant Language\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Dominant_Language\", \"complete_Malay\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "if tot_n != 0:\n",
        "    df.loc[len(df.index)] = [\"Malay\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Dominant_Language\", \"complete_English\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "if tot_n != 0:\n",
        "    df.loc[len(df.index)] = [\"English\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"Dominant_Language\", \"complete_Other\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "if tot_n != 0:\n",
        "    df.loc[len(df.index)] = [\"Other\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]"
      ],
      "metadata": {
        "id": "bewoV2UJAwrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[len(df.index)] = [\"Based on First Language\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"First_Language\", \"complete_Malay\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "if tot_n != 0:\n",
        "    df.loc[len(df.index)] = [\"Malay\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"First_Language\", \"complete_English\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "if tot_n != 0:\n",
        "    df.loc[len(df.index)] = [\"English\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n",
        "\n",
        "cs_n, mal_n, eng_n, mal_wrd, eng_wrd = generate_stats(\"First_Language\", \"complete_Other\")\n",
        "tot_n = cs_n + mal_n + eng_n\n",
        "tot_wrd = eng_wrd + mal_wrd\n",
        "if tot_n != 0:\n",
        "    df.loc[len(df.index)] = [\"Other\", cs_n, eng_n, mal_n, tot_n, round(cs_n*100/tot_n, 2), eng_wrd, mal_wrd, tot_wrd, round(eng_wrd*100/tot_wrd, 2), round(100 * (1 - (max(eng_wrd/tot_wrd, mal_wrd/tot_wrd)) ), 2) ]\n"
      ],
      "metadata": {
        "id": "eHBQn1NTA0b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(\"Results.xlsx\", index = False)"
      ],
      "metadata": {
        "id": "bCQyhakhA2KM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}