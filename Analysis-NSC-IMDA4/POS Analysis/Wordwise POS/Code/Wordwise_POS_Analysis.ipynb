{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM9Kyxp7IA-u"
      },
      "outputs": [],
      "source": [
        "# Installing the Required Libraries\n",
        "!pip -q install h5py\n",
        "!pip -q install typing-extensions\n",
        "!pip -q install wheel\n",
        "!pip -q install imgaug==0.2.5\n",
        "!pip -q install malaya\n",
        "!pip -q install tensorflow==2.9.0\n",
        "!pip -q install tensorflow_addons\n",
        "!pip -q install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re\n",
        "import malaya\n",
        "import math\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import xlsxwriter\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')"
      ],
      "metadata": {
        "id": "HIVeQpnkIDDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = malaya.pos.transformer(model = 'bert')"
      ],
      "metadata": {
        "id": "qxryNvCgIEsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mal_noun = [\"NOUN\",\"PROPN\"]\n",
        "mal_pron = [\"PRON\"]\n",
        "mal_verb = [\"ADX\",\"VERB\"]\n",
        "mal_adv = [\"ADV\"]\n",
        "mal_adj = [\"ADJ\"]\n",
        "mal_adp = [\"ADP\"]\n",
        "mal_conj = [\"CCONJ\",\"SCONJ\"]\n",
        "mal_det = [\"DET\"]\n",
        "mal_par = [\"PART\"]\n",
        "mal_num = [\"NUM\"]\n",
        "mal_sym = [\"SYM\"]\n",
        "mal_oth = [\"X\"]\n",
        "\n",
        "eng_noun = [\"NN\",\"NNP\",\"NNPS\",\"NNS\"]\n",
        "eng_pron = [\"PRP\",\"PRP$\",\"WP\",\"WP$\"]\n",
        "eng_verb = [\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\",\"MD\"]\n",
        "eng_adv = [\"RB\",\"RBR\",\"RBS\"]\n",
        "eng_adj = [\"JJ\",\"JJR\",\"JJS\"]\n",
        "eng_adp = [\"IN\"]\n",
        "eng_conj = [\"CC\"]\n",
        "eng_det = [\"DT\",\"PDT\",\"TO\",\"EX\"]\n",
        "eng_par = [\"RP\"]\n",
        "eng_num = [\"CD\"]\n",
        "eng_sym = [\"$\",\"(\",\")\",\",\",\"--\",\".\",\":\",\"SYM\",\"``\",\"''\"]\n",
        "eng_oth = [\"FW\",\"LS\",\"POS\",\"UH\"]\n"
      ],
      "metadata": {
        "id": "d5TkIgDcIGQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def english_pos(phrase,english_arr):\n",
        "            phrase = re.sub(r'[^\\w\\s]', '', phrase)\n",
        "            tokenized_sentence = word_tokenize(phrase)\n",
        "            resulting_model = nltk.pos_tag(tokenized_sentence)\n",
        "            for i in range(len(resulting_model)):\n",
        "                pos = resulting_model[i][1]\n",
        "                if pos in eng_noun:\n",
        "                    english_arr[0] += 1\n",
        "                elif pos in eng_pron:\n",
        "                    english_arr[1] += 1\n",
        "                elif pos in eng_verb:\n",
        "                    english_arr[2] += 1\n",
        "                elif pos in eng_adv:\n",
        "                    english_arr[3] += 1\n",
        "                elif pos in eng_adj:\n",
        "                    english_arr[4] += 1\n",
        "                elif pos in eng_adp:\n",
        "                    english_arr[5] += 1\n",
        "                elif pos in eng_conj:\n",
        "                    english_arr[6] += 1\n",
        "                elif pos in eng_det:\n",
        "                    english_arr[7] += 1\n",
        "                elif pos in eng_par:\n",
        "                    english_arr[8] += 1\n",
        "                elif pos in eng_num:\n",
        "                    english_arr[9] += 1\n",
        "                elif pos in eng_sym:\n",
        "                    english_arr[10] += 1\n",
        "                else:\n",
        "                    english_arr[11] += 1\n",
        "            return english_arr"
      ],
      "metadata": {
        "id": "FM7NrrM2IH7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def malay_pos(phrase, malay_arr):\n",
        "            phrase = re.sub(r'[^\\w\\s]', '', phrase)\n",
        "            resulting_model = model.analyze(phrase)\n",
        "            for i in range(len(resulting_model)):\n",
        "                pos = resulting_model[i][\"type\"]\n",
        "                if pos in mal_noun:\n",
        "                    malay_arr[0] += 1\n",
        "                elif pos in mal_pron:\n",
        "                    malay_arr[1] += 1\n",
        "                elif pos in mal_verb:\n",
        "                    malay_arr[2] += 1\n",
        "                elif pos in mal_adv:\n",
        "                    malay_arr[3] += 1\n",
        "                elif pos in mal_adj:\n",
        "                    malay_arr[4] += 1\n",
        "                elif pos in mal_adp:\n",
        "                    malay_arr[5] += 1\n",
        "                elif pos in mal_conj:\n",
        "                    malay_arr[6] += 1\n",
        "                elif pos in mal_det:\n",
        "                    malay_arr[7] += 1\n",
        "                elif pos in mal_par:\n",
        "                    malay_arr[8] += 1\n",
        "                elif pos in mal_num:\n",
        "                    malay_arr[9] += 1\n",
        "                elif pos in mal_sym:\n",
        "                    malay_arr[10] += 1\n",
        "                else:\n",
        "                    malay_arr[11] += 1\n",
        "            return malay_arr"
      ],
      "metadata": {
        "id": "BhLucfB7IJ3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def single_pos(filename):\n",
        "    with open(filepath) as f:\n",
        "        data = f.readlines()\n",
        "    f.close()\n",
        "    english_ar = [0]*(n-1)\n",
        "    malay_ar = [0]*(n-1)\n",
        "    eng_flag = False\n",
        "    mal_flag = False\n",
        "    for line in data:\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if word.starswith(\"<english>\") and word.endswith(\"</english>\")):\n",
        "                english_ar = english_pos(word[9:-10],english_ar)\n",
        "            elif word.starswith(\"<english>\"):\n",
        "                english_ar = english_pos(word[9:],english_ar)\n",
        "                eng_flag = True\n",
        "            elif word.endswith(\"</english>\"):\n",
        "                eng_flag = False\n",
        "                english_ar = english_pos(word[:-10],english_ar)\n",
        "            elif eng_flag:\n",
        "                english_ar = english_pos(word,english_ar)\n",
        "            elif word.starswith(\"<malay>\") and word.endswith(\"</malay>\"):\n",
        "                malay_ar = malay_pos(word[7:-8],malay_ar)\n",
        "            elif word.starswith(\"<malay>\"):\n",
        "                malay_ar = malay_pos(word[7:],malay_ar)\n",
        "                mal_flag = True\n",
        "            elif word.endswith(\"</malay>\"):\n",
        "                mal_flag = False\n",
        "                malay_ar = malay_pos(word[:-8],malay_ar)\n",
        "            elif mal_flag:\n",
        "                malay_ar = malay_pos(word,malay_ar)\n",
        "\n",
        "            elif word.starswith(\"<interjection>\") and word.endswith(\"</interjection>\")):\n",
        "                english_ar = english_pos(word[14:-15],english_ar)\n",
        "            elif word.starswith(\"<interjection>\"):\n",
        "                english_ar = english_pos(word[14:],english_ar)\n",
        "                eng_flag = True\n",
        "            elif word.endswith(\"</interjection>\"):\n",
        "                eng_flag = False\n",
        "                english_ar = english_pos(word[:-15],english_ar)\n",
        "            elif eng_flag:\n",
        "                english_ar = english_pos(word,english_ar)\n",
        "    return english_ar, malay_ar"
      ],
      "metadata": {
        "id": "hSYTy8dUJkv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "order = [\"Noun\", \"Pronoun\", \"Verb\", \"Adverb\", \"Adjective\", \"Adposition\", \"Conjunction\", \"Determiner\", \"Particle\", \"Number\", \"Symbol\", \"Other\", \"Total\"]\n",
        "head = [\"Part of Speech\", \"No of English Words\", \"No of Malay Words\",\"Total no of Words\", \"Substitution Rate\", \"CMI\"]\n",
        "n = len(order)"
      ],
      "metadata": {
        "id": "vk7DYHGhIM7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def analyzer(english_arr,malay_arr):\n",
        "    k = []\n",
        "    for i in range(n-1):\n",
        "        if english_arr[i] == 0 and malay_arr[i] == 0:\n",
        "            k.append([order[i], english_arr[i], malay_arr[i], english_arr[i]+malay_arr[i], \"NA\", \"NA\", \"NA\", \"NA\"])\n",
        "        else:\n",
        "            P_eng = english_arr[i]/(english_arr[i] + malay_arr[i])\n",
        "            P_mal = 1 - P_eng\n",
        "            eng_substitution_rate = \"{:.2f}\".format(P_eng * 100)\n",
        "            CMI = \"{:.2f}\".format(100 * (1 - (max(P_eng,P_mal)) ))\n",
        "            k.append([order[i], english_arr[i], malay_arr[i], english_arr[i]+malay_arr[i], eng_substitution_rate,CMI])\n",
        "    eng = sum(english_arr)\n",
        "    mal = sum(malay_arr)\n",
        "    if eng == 0 and mal == 0:\n",
        "        k.append([order[-1], eng, mal, eng+mal, \"NA\", \"NA\", \"NA\", \"NA\"])\n",
        "    else:\n",
        "        P_eng = eng/(eng+mal)\n",
        "        P_mal = 1 - P_eng\n",
        "        eng_substitution_rate = \"{:.2f}\".format(P_eng * 100)\n",
        "        CMI = \"{:.2f}\".format(100 * (1 - (max(P_eng,P_mal)) ))\n",
        "        k.append([order[-1], eng, mal, eng+mal, eng_substitution_rate,CMI])\n",
        "    df = pd.DataFrame(k, columns = head).set_index('Part of Speech')\n",
        "    return df"
      ],
      "metadata": {
        "id": "8w_kJdOQISLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_ar, malay_ar = single_pos(\"CS_Lang_Data.txt\")\n",
        "df = analyzer(english_ar,malay_ar)\n",
        "df.to_excel(\"POS_results.xlsx\")"
      ],
      "metadata": {
        "id": "tlwYxXukIm1W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}